## Description
Created as part of my first year university coursework.

The task was to create a program that would run on a Brunel University SwiftBot allow the robot to successfuly navigate towards brighter areas around it. The robot itself is a raspberry pi with some cameras, ultrasound measurer, wheels etc attached to it. 
This was one of the toughest tasks that we were allowed to choose from but I knew it would be fun learning a bit of image processing so I chose it. I had plenty of spare time so I implemented some bonus features like having it move towards darker areas of the room, more indepth collision avoidance etc. 
<br/>

At the end of execution (either due to object obstruction or manual termination) the swiftbot will provide any logged data. <br/>
Here is the general format the data will be displayed as:<br/>
![cmd_hFDP1DjSum](https://github.com/user-attachments/assets/f276b7fe-dafc-4773-bda4-b67032ab70dc)


<br/><br/><br/>
Here are the design flowcharts, if anyone is curious: <br/>
https://drive.google.com/drive/folders/1xPHhCPJqCguIFok1j0V7CAUQWGwHFB6q?usp=sharing

<br/>
![image](https://github.com/user-attachments/assets/1a999209-ba6c-466c-8708-4163b274e4f9)
<br/>
Image credit: Brunel University London


